# ðŸ“° Rapport de veille hebdomadaire
_GÃ©nÃ©rÃ© automatiquement le 08/04/2025_

## [The Power of Fine-Tuning on Your Data: Quick Fixing Bugs with LLMs via Never Ending Learning (NEL)](https://www.databricks.com/blog/power-fine-tuning-your-data-quick-fixing-bugs-llms-never-ending-learning-nel)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Databricks

> Quick Fix helps users resolve errors by suggesting code fixes in-line. We focus on the task of program repair which requires fixing bugs in code. In this blog, we demonstrate how fine-tuning a small open-source LLM on interaction dataÂ enables state-of-the-art accuracy, low cost, and minimal latency.
---
## [Databricks Wins 2025 Google Cloud Partner of the Year Award](https://www.databricks.com/blog/databricks-wins-2025-google-cloud-partner-year-award)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Databricks

> Databricks named 2025 Google Cloud Data & Analytics Partner of the Year for Smart Analytics.Recognized for AI innovation, customer success, and deep product integration.Join us at Google Cloud Next and Data + AI Summit to learn whatâ€™s next Databricks Secures Google Cloud Technology Partner of The Year Award.
---
## [Sample, Don't Search: Rethinking Test-Time Alignment for Language Models](https://huggingface.co/papers/2504.03790)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Increasing test-time computation has emerged as a promising direction forimproving language model performance. However, existing search methods using a reward model often degrade in quality as compute scales, due to the inherently imperfect reward proxies. We introduce an approach called QAlign, which enables better-aligned outputs without modifying the underlying model.
---
## [Rethinking Reflection in Pre-Training](https://huggingface.co/papers/2504.04022)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> A language model's ability to reflect on its own reasoning provides a key advantage for solving complex problems. While most recent research has focused on how this ability develops during reinforcement learning, we show that it actually begins to emerge much earlierâ€”during themodelâ€™s pre-training. We introduce deliberate errors into chains-of-thought and test whether the model can still arrive at the correct answer by recognizing andcorrecting these mistakes.
---
## [Rethinking Multilingual Continual Pretraining: Data Mixing for Adapting
  LLMs Across Languages and Resources](https://huggingface.co/papers/2504.04152)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Large Language Models (LLMs) exhibit significant disparities in performanceacross languages. Continual Pretraining (CPT) has emerged as a promising approach to address this imbalance. The relative effectiveness of monolingual, bilingual, and code-augmented data strategies remains unclear. Bilingual CPT improves multilingual classification but often causes language mixing issues during generation.
---
## [GlotEval: A Test Suite for Massively Multilingual Evaluation of Large
  Language Models](https://huggingface.co/papers/2504.04155)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> GlotEval is a framework designed for massively multilingual evaluation. It highlights consistent multilingual benchmarking, language-specific templates, and non-English-centric machine translation. The framework supports seven key tasks (machine translation, text classification, open-ended generation, reading comprehension, sequence labeling) spanning over dozens to hundreds of languages.
---
## [VAPO: Efficient and Reliable Reinforcement Learning for Advanced
  Reasoning Tasks](https://huggingface.co/papers/2504.05118)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> VAPO is a novel framework tailored for reasoning models within the value-based paradigm. It reaches state-of-the-art performance within amere 5,000 steps. VAPO outperforms the previously reported results of DeepSeek-R1-Zero-Qwen-32B and DAPO.
---
## [Mamba as a Bridge: Where Vision Foundation Models Meet Vision Language
  Models for Domain-Generalized Semantic Segmentation](https://huggingface.co/papers/2504.03193)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Vision Foundation Models (VFMs) and Vision-Language Models (VLMs) have gained traction in Domain Generalized Semantic Segmentation. VFMs excel at capturing fine-grained features, while VLMs provide robust text alignment but struggle with coarse granularity. We propose a novel Mamba-based fusion framework that efficiently combines the strengths of VFm and VLm while maintaining linear scalability.
---
## [DiaTool-DPO: Multi-Turn Direct Preference Optimization for
  Tool-Augmented Large Language Models](https://huggingface.co/papers/2504.02882)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Tool-Augmented Larage Language Models (TA-LLMs) face challenges in handling incomplete queries andout-of-scope requests. We propose DiaTool-DPO, a novel method that enhances TA-LLM's dialogue capabilities through Direct PreferenceOptimization. Our approach opens new possibilities fo the development of new tools.
---
## [SmolVLM: Redefining small and efficient multimodal models](https://huggingface.co/papers/2504.05299)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Large Vision-Language Models (VLMs) deliver exceptional performance but require significant computational resources. Smaller VLMs typically mirror design choices of larger models, leading to inefficient GPU memory usage and constrained practicality for on-device applications. We introduce SmolVLM, a series of compact multimodal models specifically engineered for resource-efficient inference.
---
## [T1: Tool-integrated Self-verification for Test-time Compute Scaling in
  Small Language Models](https://huggingface.co/papers/2504.04718)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Small language models (sLMs) struggle with verification tasks requiring memorization, such as numerical calculations and fact-checking. Tool-integrated self-verification delegates memororization-heavy verification steps to external tools. Our theoretical analysis shows that tool integration reducesMemorization demands and improves test-time scaling performance.
---
## [Clinical ModernBERT: An efficient and long context encoder for
  biomedical text](https://huggingface.co/papers/2504.03964)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Clinical ModernBERT is a transformer based encoder pretrained on large scale biomedical literature, clinical notes, and medical ontologies. It excels at producing semantically richrepresentations tailored for long context tasks. We validate this both by analyzing its pretrained weights and through empirical evaluation on a suite of clinical NLP benchmarks.
---
## [BOP Challenge 2024 on Model-Based and Model-Free 6D Object Pose
  Estimation](https://huggingface.co/papers/2504.02812)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> The BOP Challenge 2024 is the sixth in a series of public competitions organized to capture the state of the art in 6D object pose estimation and related tasks. The goal was to transition BOP from lab-like setups to real-world scenarios. Participants competed on seven challenge tracks, each defined by a task, objectonboarding setup, and dataset group.
---
## [LiveVQA: Live Visual Knowledge Seeking](https://huggingface.co/papers/2504.05288)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> LiveVQA is an automatically collected dataset of latest visual knowledge from the Internet with synthesized VQA problems. It consists of 6 news websites across 14news categories, featuring high-quality image-text coherence and authentic information. Stronger models perform better overall, with advanced visual reasoning capabilities proving crucial for complex multi-hop questions.
---
## [Quantization Hurts Reasoning? An Empirical Study on Quantized Reasoning
  Models](https://huggingface.co/papers/2504.04823)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Quantization has been widely adopted to reduce the inference cost of large language models. Our investigation covers weight, KV cache, andactivation quantization using state-of-the-art algorithms. While lossless quantization can be achieved with W8A8 or W4A16 quantization, lower bit-widths introduce significant accuracy risks.
---
## [JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language
  Model](https://huggingface.co/papers/2504.03770)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Multimodal large language models (MLLMs) excel in vision-language tasks but also pose significant risks of generating harmful content. Jailbreak attacks refer to intentional manipulations that lead to the generation of inappropriate or unsafe content. Detecting such attacks is critical to ensuring theresponsible deployment of MLLMs.
---
## [Concept Lancet: Image Editing with Compositional Representation
  Transplant](https://huggingface.co/papers/2504.02828)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Concept Lancet (CoLan) is a zero-shot plug-and-playframework for principled representation manipulation in diffusion-based image editing. We decompose the source input in the latent (textembedding or diffusion score) space as asparse linear combinationof the collectedvisual concepts. This allows us to accuratelyestimate the presence of concepts in each image, which informs the edit.
---
## [Are You Getting What You Pay For? Auditing Model Substitution in LLM
  APIs](https://huggingface.co/papers/2504.04715)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Large Language Models (LLMs) accessed via black-box APIs. Users pay for services based on capabilities (e.g., size, performance), but providers may substitute the specified model with a cheaper, lower-quality alternative. Detecting such such substitutions is difficult due to the black- box nature.
---
## [One-Minute Video Generation with Test-Time Training](https://huggingface.co/papers/2504.05298)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Transformers today struggle to generate one-minute videos because self-attention layers are inefficient for long context. We experiment with Test-Time Training (TTT) layers, whose hidden states themselves can be neural networks, therefore more expressive. Compared to baselines such as Mamba~2, Gated DeltaNet, and sliding-window attention layers, TTT layers can tell complex stories.
---
## [URECA: Unique Region Caption Anything](https://huggingface.co/papers/2504.05305)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Region-level captioning aims to generate natural language descriptions for specific image regions. URECA dataset ensures a unique and consistent mapping between regions and captions. Central to this is a stage-wise data curation pipeline, where each stage incrementally refines region selection and caption generation.
---
## [Gaussian Mixture Flow Matching Models](https://huggingface.co/papers/2504.05304)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Feed for https://jamesg.blog/hf-papers.json

> Diffusion models approximate the denoising distribution as a Gaussian and predicting its mean. Flow matching models reparameterize the Gaussian mean as flow velocity. GMFlow predicts dynamic Gaussian mixture (GM) parameters to capture a multi-modal flow velocity distribution. We demonstrate that GMFlow generalizes previous diffusion andflow matching models.
---
## [Arabic Leaderboards: Introducing Arabic Instruction Following, Updating AraGen, and More](https://huggingface.co/blog/leaderboard-3c3h-aragen-ifeval)
**ðŸ•“ Date** : 08/04/2025  
**ðŸ“¡ Source** : Hugging Face - Blog

> Arabic-Leaderboards is a comprehensive and unified space for all Arabic evaluations and tasks. It is meant to serve as a central hub covering a broad spectrum of evaluations, for models across modalities. Currently, it has AraGen-03-25 and Arabic Instruction Following as live leaderboards.
---
## [Databricks Bengaluru: Scaling Innovation and Building the Future of Data & AI](https://www.databricks.com/blog/databricks-bengaluru-scaling-innovation-and-building-future-data-ai)
**ðŸ•“ Date** : 07/04/2025  
**ðŸ“¡ Source** : Databricks

> Databricksâ€™ R&D hub in Bengaluru is expanding. Discover how our engineering teams are helping to solve the worldâ€™s toughest problems. Weâ€™re hiring top engineers to build next-gen AI and data platforms. At Databricks, we help our customers solve their problems by leveraging data and AI.
---
## [Announcing the APJ Databricks Smart Business Insights Challenge: Empowering Data-Driven Decision Making with AI and BI](https://www.databricks.com/blog/announcing-apj-databricks-smart-business-insights-challenge-empowering-data-driven-decision)
**ðŸ•“ Date** : 07/04/2025  
**ðŸ“¡ Source** : Databricks

> The Databricks Smart Business Insights Challenge is a virtual hackathon for data analysts, BI professionals, data engineers, and scientists to team up with business users and domain experts. This challenge provides a unique opportunity to work together, apply AI-driven BI tools and solve real-world business problems for a chance to win exciting prizes.
---
## [Introducing Metaâ€™s Llama 4 on the Databricks Data Intelligence Platform](https://www.databricks.com/blog/introducing-metas-llama-4-databricks-data-intelligence-platform)
**ðŸ•“ Date** : 05/04/2025  
**ðŸ“¡ Source** : Databricks

> Llama 4 Maverick is now available on Databricks across AWS, Azure, and GCP. Built-in governance, including built-in logging, rate limiting, PII detection, and policy guardrails, helps to ensure safe use in production. Develop and deploy fast, cost-effective, domain-specific agents, copilots, and RAG pipelines that use your data.
---
## [Welcome Llama 4 Maverick & Scout on Hugging Face!](https://huggingface.co/blog/llama4-release)
**ðŸ•“ Date** : 05/04/2025  
**ðŸ“¡ Source** : Hugging Face - Blog

> Llama 4 Maverick and Scout are the next generation of large language models from Meta. Released today, these powerful, natively multimodal models represent a significant leap forward. We've worked closely with Meta to ensure seamless integration into the Hugging Face ecosystem, including both transformers and TGI from day one.
---
## [Journey to 1 Million Gradio Users!](https://huggingface.co/blog/gradio-1m)
**ðŸ•“ Date** : 04/04/2025  
**ðŸ“¡ Source** : Hugging Face - Blog

> 5 years ago, we launched Gradio as a simple Python library to let researchers at Stanford easily demo computer vision models with a web interface. Today, Gradio is used by >1 million developers each month to build and share AI web apps. This includes some of the most popular open-source projects of all time, likeAutomatic1111.
---
## [The NLP Course is becoming the LLM Course!](https://huggingface.co/blog/llm-course)
**ðŸ•“ Date** : 03/04/2025  
**ðŸ“¡ Source** : Hugging Face - Blog

> OurNLP course has been a go-to resource for the open-source AI community for the past 3 years. Weâ€™re updating and expanding it to keep up with all the exciting stuff happening in AI. Over the last few months weâ€™ve expanded the "NLP" course with new chapters, including fine-tuning LLMs.
---
## [Announcing the Built-On Databricks Startup Challenge](https://www.databricks.com/blog/announcing-built-databricks-startup-challenge)
**ðŸ•“ Date** : 02/04/2025  
**ðŸ“¡ Source** : Databricks

> Built-On Databricks Startup Challenge offers $1M in prizes for early-stage startups building core, customer-facing B2B products. Open to current databricks customers who use Databrick as a core part of the architecture powering a customer- facing application. Participating startups will be judged on how they use the data intelligence platform.
---
## [Databricks on Google Cloud: Innovations Driving Data Intelligence](https://www.databricks.com/blog/databricks-google-cloud-innovations-driving-data-intelligence)
**ðŸ•“ Date** : 02/04/2025  
**ðŸ“¡ Source** : Databricks

> Databricks on Google Cloud has provided more than 1,500 joint customers with a tightly integrated experience. Both Databricks and Google Cloud have experienced accelerated growth in the past year. In Q4 of 2024 Google Cloud generated $12 billion in revenue, a 30% increase YoY.
---
## [Announcing the General Availability of Lakeflow Connect](https://www.databricks.com/blog/announcing-general-availability-lakeflow-connect)
**ðŸ•“ Date** : 02/04/2025  
**ðŸ“¡ Source** : Databricks

> Lakeflow Connect enables use cases such as analyzing consumer behavior, predicting churn, and centralizing HR analytics. Salesforce Sales Cloud and Workday provide a simple and scalable method to ingest data into Databricks. Lakeflow Connect introduces no-code ingestion connectors for popular SaaS applications, databases, and file sources.
---